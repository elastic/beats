#!/usr/bin/env groovy

@Library('apm@feature/2.0-beats') _

import groovy.transform.Field
/**
 This is required to store the stashed id with the test results to be digested with runbld
*/
@Field def stashedTestReports = [:]

pipeline {
  agent { label 'ubuntu-18 && immutable' }
  environment {
    AWS_ACCOUNT_SECRET = 'secret/observability-team/ci/elastic-observability-aws-account-auth'
    BASE_DIR = 'src/github.com/elastic/beats'
    DOCKERELASTIC_SECRET = 'secret/observability-team/ci/docker-registry/prod'
    DOCKER_COMPOSE_VERSION = "1.21.0"
    DOCKER_REGISTRY = 'docker.elastic.co'
    GOX_FLAGS = "-arch amd64"
    JOB_GCS_BUCKET = 'beats-ci-temp'
    JOB_GCS_CREDENTIALS = 'beats-ci-gcs-plugin'
    PIPELINE_LOG_LEVEL = 'INFO'
    OSS_MODULE_PATTERN = '^[a-z0-9]+beat\\/module\\/([^\\/]+)\\/.*'
    RUNBLD_DISABLE_NOTIFICATIONS = 'true'
    TERRAFORM_VERSION = "0.12.24"
    XPACK_MODULE_PATTERN = '^x-pack\\/[a-z0-9]+beat\\/module\\/([^\\/]+)\\/.*'
  }
  options {
    timeout(time: 2, unit: 'HOURS')
    buildDiscarder(logRotator(numToKeepStr: '20', artifactNumToKeepStr: '20', daysToKeepStr: '30'))
    timestamps()
    ansiColor('xterm')
    disableResume()
    durabilityHint('PERFORMANCE_OPTIMIZED')
    quietPeriod(10)
    rateLimitBuilds(throttle: [count: 60, durationName: 'hour', userBoost: true])
  }
  triggers {
    issueCommentTrigger('(?i)(.*(?:jenkins\\W+)?run\\W+(?:the\\W+)?tests(?:\\W+please)?.*|^/test\\W+.*$)')
  }
  parameters {
    booleanParam(name: 'allCloudTests', defaultValue: false, description: 'Run all cloud integration tests.')
    booleanParam(name: 'awsCloudTests', defaultValue: false, description: 'Run AWS cloud integration tests.')
    string(name: 'awsRegion', defaultValue: 'eu-central-1', description: 'Default AWS region to use for testing.')
    booleanParam(name: 'runAllStages', defaultValue: false, description: 'Allow to run all stages.')
    booleanParam(name: 'macosTest', defaultValue: false, description: 'Allow macOS stages.')
    booleanParam(name: 'windowsTest', defaultValue: true, description: 'Allow Windows stages.')
    booleanParam(name: 'debug', defaultValue: false, description: 'Allow debug logging for Jenkins steps')
  }
  stages {
    stage('Checkout') {
      options { skipDefaultCheckout() }
      steps {
        pipelineManager([ cancelPreviousRunningBuilds: [ when: 'PR' ] ])
        deleteDir()
        gitCheckout(basedir: "${BASE_DIR}", githubNotifyFirstTimeContributor: true)
        stashV2(name: 'source', bucket: "${JOB_GCS_BUCKET}", credentialsId: "${JOB_GCS_CREDENTIALS}")
        dir("${BASE_DIR}"){
          // Skip all the stages except docs for PR's with asciidoc and md changes only
          setEnvVar('ONLY_DOCS', isGitRegionMatch(patterns: [ '.*\\.(asciidoc|md)' ], shouldMatchAll: true).toString())
          setEnvVar('GO_VERSION', readFile(".go-version").trim())
          withEnv(["HOME=${env.WORKSPACE}"]) {
            retryWithSleep(retries: 2, seconds: 5){ sh(label: "Install Go ${env.GO_VERSION}", script: '.ci/scripts/install-go.sh') }
          }
        }
      }
    }
    stage('Lint'){
      options { skipDefaultCheckout() }
      environment {
        GOFLAGS = '-mod=readonly'
      }
      when {
        anyOf {
          not { changeRequest() }                           // If no PR
          allOf {                                           // If PR and no docs changes
            expression { return env.ONLY_DOCS == "false" }
            changeRequest()
          }
          expression { return params.runAllStages }         // If UI forced
        }
      }
      steps {
        whenFalse(true) { // TODO: disable for the time being.
          makeTarget(context: "Lint", target: "check")
        }
      }
    }
    stage('Build&Test') {
      options { skipDefaultCheckout() }
      steps {
        deleteDir()
        unstashV2(name: 'source', bucket: "${JOB_GCS_BUCKET}", credentialsId: "${JOB_GCS_CREDENTIALS}")
        dir("${BASE_DIR}"){
          script {
            def mapParallelTasks = [:]
            def content = readYaml(file: 'Jenkinsfile.yml')
            content['projects'].each { projectName ->
              generateStages(project: projectName, changeset: content['changeset']).each { k,v ->
                mapParallelTasks["${k}"] = v
              }
            }
            parallel(mapParallelTasks)
          }
        }
      }
      post {
        always {
          dir("${BASE_DIR}"){
            // Archive the markdown files that contain the build reasons
            archiveArtifacts(allowEmptyArchive: false, artifacts: 'build-reasons/*.md')
          }
        }
      }
    }
  }
  post {
    always {
      runbld()
    }
    cleanup {
      notifyBuildResult(prComment: true)
    }
  }
}

/**
* This method is the one used for running the parallel stages, therefore
* its arguments are passed by the beatsStages step.
*/
def generateStages(Map args = [:]) {
  def projectName = args.project
  def changeset = args.changeset
  def mapParallelStages = [:]
  def fileName = "${projectName}/Jenkinsfile.yml"
  if (fileExists(fileName)) {
    def content = readYaml(file: fileName)
    if (beatsWhen(project: projectName, content: content?.when, changeset: changeset)) {
      mapParallelStages = beatsStages(project: projectName, content: content, changeset: changeset, function: this.&runCommand)
    }
  } else {
    log(level: 'WARN', text: "${fileName} file does not exist. Please review the top-level Jenkinsfile.yml")
  }
  return mapParallelStages
}

/**
* This method is the one used for running the parallel stages, therefore
* its arguments are passed by the beatsStages step.
*
*  What parameters/arguments are supported:
*    - label -> the worker labels
*    - project -> the name of the project that should match with the folder name.
*    - content -> the specific stage data in the <project>/Jenkinsfile.yml
*/
def runCommand(Map args = [:]) {
  def withModule = args.content.get('withModule', false)
  if(args?.content?.containsKey('make')) {
    makeTarget(context: args.label, command: args.content.make, directory: args.project, label: args.label, withModule: withModule)
  }
  if(args?.content?.containsKey('mage')) {
    mageTarget(context: args.label, command: args.content.mage, directory: args.project, label: args.label, withModule: withModule)
  }
  if(args?.content?.containsKey('k8sTest')) {
    k8sTest(versions: args.content.k8sTest.split('-'), label: args.label)
  }
  if(args?.content?.containsKey('cloud')) {
    cloud(context: args.label, command: args.content.cloud, directory: args.project, label: args.label, withModule: withModule)
  }
}

def cloud(Map args = [:]) {
  node(args.label) {
    stage("${args.contex}-prepare-cloud-env"){
      startCloudTestEnv(args.context, dirs: ['x-pack/metricbeat/module/aws'])
    }
  }
  withCloudTestEnv() {
    mageTarget(context: args.context, command: args.command, directory: args.directory, label: args.label, withModule: args.withModule)
  }
}

def k8sTest(Map args = [:]) {
  def versions = args.versions
  node(args.label) {
    versions.each{ v ->
      stage("k8s ${v}"){
        withEnv(["K8S_VERSION=${v}", "KIND_VERSION=v0.7.0", "KUBECONFIG=${env.WORKSPACE}/kubecfg"]){
          withGithubNotify(context: "K8s ${v}") {
            withBeatsEnv(archive: false, withModule: false) {
              retryWithSleep(retries: 2, seconds: 5, backoff: true){ sh(label: "Install kind", script: ".ci/scripts/install-kind.sh") }
              retryWithSleep(retries: 2, seconds: 5, backoff: true){ sh(label: "Install kubectl", script: ".ci/scripts/install-kubectl.sh") }
              try {
                sh(label: "Setup kind", script: ".ci/scripts/kind-setup.sh")
                sh(label: "Integration tests", script: "MODULE=kubernetes make -C metricbeat integration-tests")
                sh(label: "Deploy to kubernetes",script: "make -C deploy/kubernetes test")
              } finally {
                sh(label: 'Delete cluster', script: 'kind delete cluster')
              }
            }
          }
        }
      }
    }
  }
}

def makeTarget(Map args = [:]) {
  def context = args.context
  def command = args.command
  def directory = args.get('directory', '')
  def withModule = args.get('withModule', false)
  node(args.label) {
    withGithubNotify(context: "${context}") {
      withBeatsEnv(archive: true, withModule: withModule, directory: directory) {
        cmd(label: "${command}", script: "${command}")
      }
    }
  }
}

def mageTarget(Map args = [:]) {
  def context = args.context
  def command = args.command
  def directory = args.directory
  def withModule = args.get('withModule', false)
  node(args.label) {
    withGithubNotify(context: "${context}") {
      withBeatsEnv(archive: true, withModule: withModule, directory: directory) {
        dir(directory) {
          cmd(label: "${command}", script: "${command}")
        }
      }
    }
  }
}

/**
* This method wraps all the environment setup and pre-requirements to run any commands.
*/
def withBeatsEnv(Map args = [:], Closure body) {
  def archive = args.get('archive', true)
  def withModule = args.get('withModule', false)
  def directory = args.get('directory', '')

  def goRoot, path, magefile, pythonEnv, testResults, artifacts

  if(isUnix()) {
    goRoot = "${env.WORKSPACE}/.gvm/versions/go${GO_VERSION}.${nodeOS()}.amd64"
    path = "${env.WORKSPACE}/bin:${goRoot}/bin:${env.PATH}"
    magefile = "${WORKSPACE}/.magefile"
    pythonEnv = "${WORKSPACE}/python-env"
    testResults = '**/build/TEST*.xml'
    artifacts = '**/build/TEST*.out'
  } else {
    def chocoPath = 'C:\\ProgramData\\chocolatey\\bin'
    def chocoPython3Path = 'C:\\Python38;C:\\Python38\\Scripts'
    goRoot = "${env.USERPROFILE}\\.gvm\\versions\\go${GO_VERSION}.windows.amd64"
    path = "${env.WORKSPACE}\\bin;${goRoot}\\bin;${chocoPath};${chocoPython3Path};${env.PATH}"
    magefile = "${env.WORKSPACE}\\.magefile"
    testResults = "**\\build\\TEST*.xml"
    artifacts = "**\\build\\TEST*.out"
  }

  deleteDir()
  unstashV2(name: 'source', bucket: "${JOB_GCS_BUCKET}", credentialsId: "${JOB_GCS_CREDENTIALS}")
  // NOTE: This is required to run after the unstash
  def module = withModule ? getCommonModuleInTheChangeSet(directory) : ''
  withEnv([
    "DOCKER_PULL=0",
    "GOPATH=${env.WORKSPACE}",
    "GOROOT=${goRoot}",
    "HOME=${env.WORKSPACE}",
    "MAGEFILE_CACHE=${magefile}",
    "MODULE=${module}",
    "PATH=${path}",
    "PYTHON_ENV=${pythonEnv}",
    "RACE_DETECTOR=true",
    "TEST_COVERAGE=true",
    "TEST_TAGS=${env.TEST_TAGS},oracle"
  ]) {
    if(isInstalled(tool: 'docker', flag: '--version')) {
      dockerLogin(secret: "${DOCKERELASTIC_SECRET}", registry: "${DOCKER_REGISTRY}")
    }
    dir("${env.BASE_DIR}") {
      installTools()
      if(isUnix()) {
        // TODO (2020-04-07): This is a work-around to fix the Beat generator tests.
        // See https://github.com/elastic/beats/issues/17787.
        sh(label: 'check git config', script: '''
          if [ -z "$(git config --get user.email)" ]; then
            git config user.email "beatsmachine@users.noreply.github.com"
            git config user.name "beatsmachine"
          fi''')
      }
      try {
        body()
      } finally {
        if (archive) {
          archiveTestOutput(testResults: testResults, artifacts: artifacts)
        }
        // Tear down the setup for the permamnent workers.
        catchError(buildResult: 'SUCCESS', stageResult: 'SUCCESS') {
          fixPermissions("${WORKSPACE}")
          deleteDir()
        }
      }
    }
  }
}

/**
* This method fixes the filesystem permissions after the build has happenend. The reason is to
* ensure any non-ephemeral workers don't have any leftovers that could cause some environmental
* issues.
*/
def fixPermissions(location) {
  if(isUnix()) {
    sh(label: 'Fix permissions', script: """#!/usr/bin/env bash
      set +x
      source ./dev-tools/common.bash
      docker_setup
      script/fix_permissions.sh ${location}""", returnStatus: true)
  }
}

/**
* This method installs the required dependencies that are for some reason not available in the
* CI Workers.
*/
def installTools() {
  if(isUnix()) {
    retryWithSleep(retries: 2, seconds: 5, backoff: true){ sh(label: "Install Go/Mage/Python/Docker/Terraform ${GO_VERSION}", script: '.ci/scripts/install-tools.sh') }
  } else {
    retryWithSleep(retries: 2, seconds: 5, backoff: true){ bat(label: "Install Go/Mage/Python ${GO_VERSION}", script: ".ci/scripts/install-tools.bat") }
  }
}

/**
* This method gathers the module name, if required, in order to run the ITs only if
* the changeset affects a specific module.
*
* For such, it's required to look for changes under the module folder and exclude anything else
* such as ascidoc and png files.
*/
def getCommonModuleInTheChangeSet(String directory) {
  // Use contains to support the makeTarget(target: '-C <folder>') while mageTarget(directory: '<folder>')
  def pattern = (directory.contains('x-pack') ? env.XPACK_MODULE_PATTERN : env.OSS_MODULE_PATTERN)
  def module = ''

  // Transform folder structure in regex format since path separator is required to be escaped
  def transformedDirectory = directory.replaceAll('/', '\\/')
  def directoryExclussion = "((?!^${transformedDirectory}\\/).)*\$"
  def exclude = "^(${directoryExclussion}|((?!\\/module\\/).)*\$|.*\\.asciidoc|.*\\.png)"
  dir("${env.BASE_DIR}") {
    module = getGitMatchingGroup(pattern: pattern, exclude: exclude)
  }
  return module
}

/**
* This method archives and report the tests output, for such, it searches in certain folders
* to bypass some issues when working with big repositories.
*/
def archiveTestOutput(Map args = [:]) {
  catchError(buildResult: 'SUCCESS', stageResult: 'UNSTABLE') {
    if (isUnix()) {
      fixPermissions("${WORKSPACE}")
    }
    cmd(label: 'Prepare test output', script: 'python .ci/scripts/pre_archive_test.py')
    dir('build') {
      junitAndStore(allowEmptyResults: true, keepLongStdio: true, testResults: args.testResults)
      archiveArtifacts(allowEmptyArchive: true, artifacts: args.artifacts)
    }
    catchError(buildResult: 'SUCCESS', message: 'Failed to archive the build test results', stageResult: 'SUCCESS') {
      def folder = cmd(label: 'Find system-tests', returnStdout: true, script: 'python .ci/scripts/search_system_tests.py').trim()
      log(level: 'INFO', text: "system-tests='${folder}'. If no empty then let's create a tarball")
      if (folder.trim()) {
        def name = folder.replaceAll('/', '-').replaceAll('\\\\', '-').replaceAll('build', '').replaceAll('^-', '') + '-' + nodeOS()
        tar(file: "${name}.tgz", archive: true, dir: folder)
      }
    }
  }
}

/**
* This method wraps the junit built-in step to archive the test reports that gonna be populated later on
* with the runbld post build step.
*/
def junitAndStore(Map args = [:]){
  junit(args)
  // STAGE_NAME env variable could be null in some cases, so let's use the currentmilliseconds
  def stageName = env.STAGE_NAME ? env.STAGE_NAME.replaceAll("[\\W]|_",'-') : "uncategorized-${new java.util.Date().getTime()}"
  stash(includes: args.testResults, allowEmpty: true, name: stageName, useDefaultExcludes: true)
  stashedTestReports[stageName] = stageName
}

/**
* This method populates the test output using the runbld approach. For such it requires the
* global variable stashedTestReports. 
*/
def runbld() {
  catchError(buildResult: 'SUCCESS', message: 'runbld post build action failed.') {
    if (stashedTestReports) {
      dir("${env.BASE_DIR}") {
        sh(label: 'Prepare workspace context',
           script: 'find . -type f -name "TEST*.xml" -path "*/build/*" -delete')
        // Unstash the test reports
        stashedTestReports.each { k, v ->
          dir(k) {
            unstash(v)
          }
        }
        sh(label: 'Process JUnit reports with runbld',
          script: '''\
          cat >./runbld-script <<EOF
          echo "Processing JUnit reports with runbld..."
          EOF
          /usr/local/bin/runbld ./runbld-script
          '''.stripIndent())  // stripIdent() requires '''/
      }
    }
  }
}

/**
* This method executes a closure with credentials for cloud test
* environments.
*/
def withCloudTestEnv(Closure body) {
  def maskedVars = []
  def testTags = "${env.TEST_TAGS}"

  // AWS
  if (params.allCloudTests || params.awsCloudTests) {
    testTags = "${testTags},aws"
    def aws = getVaultSecret(secret: "${AWS_ACCOUNT_SECRET}").data
    if (!aws.containsKey('access_key')) {
      error("${AWS_ACCOUNT_SECRET} doesn't contain 'access_key'")
    }
    if (!aws.containsKey('secret_key')) {
      error("${AWS_ACCOUNT_SECRET} doesn't contain 'secret_key'")
    }
    maskedVars.addAll([
      [var: "AWS_REGION", password: params.awsRegion],
      [var: "AWS_ACCESS_KEY_ID", password: aws.access_key],
      [var: "AWS_SECRET_ACCESS_KEY", password: aws.secret_key],
    ])
  }

  withEnv([
    "TEST_TAGS=${testTags}",
  ]) {
    withEnvMask(vars: maskedVars) {
      body()
    }
  }
}

/**
* Start testing environment on cloud using terraform. Terraform files are
* stashed so they can be used by other stages. They are also archived in
* case manual cleanup is needed.
*
* Example:
*   startCloudTestEnv('x-pack-metricbeat', dir: ['x-pack/metricbeat/module/aws'])
*   ...
*   terraformCleanup('x-pack-metricbeat', 'x-pack/metricbeat')
*/
def startCloudTestEnv(String name, dirs = []) {
  withCloudTestEnv() {
    withBeatsEnv(archive: false, withModule: false) {
      try {
        for (folder in dirs) {
          retryWithSleep(retries: 2, seconds: 5, backoff: true){
            terraformApply(folder)
          }
        }
      } finally {
        // Archive terraform states in case manual cleanup is needed.
        archiveArtifacts(allowEmptyArchive: true, artifacts: '**/terraform.tfstate')
      }
      stash(name: "terraform-${name}", allowEmpty: true, includes: '**/terraform.tfstate,**/.terraform/**')
    }
  }
}

/**
* Tear down the terraform environments, by looking for all terraform states in directory 
* then it runs terraform destroy for each one.
* it uses terraform states previously stashed by startCloudTestEnv.
*/
def terraformCleanup(String stashName, String directory) {
  stage("Remove cloud scenarios in ${directory}"){
    withCloudTestEnv() {
      withBeatsEnv(archive: false, withModule: false) {
        unstash("terraform-${stashName}")
        retryWithSleep(retries: 2, seconds: 5, backoff: true) {
          sh(label: "Terraform Cleanup", script: ".ci/scripts/terraform-cleanup.sh ${directory}")
        }
      }
    }
  }
}