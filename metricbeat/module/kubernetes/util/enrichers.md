### Kubernetes metrics metadata enrichment

- The following description is irrelevant to the metadata enrichment that happens due to the `add_kubernetes_metadata` processor and Kubernetes provider.
- The `add_kubernetes_metadata` processor is skipped in cases of Kubernetes module for metrics collection. It is only used in the case of logs collection when the Kubernetes autodiscover provider is not used.
-The Kubernetes autodiscover provider enriches with metadata mainly when it comes to log collection when it is configured. It is by default in the `container_logs` integration in the Elastic Agent.
- Metadata enrichment from the enrichers happens for all the following Kubernetes metricsets: `state_namespace`, `state_node`, `state_deployment`, `state_daemonset`, `state_replicaset`, `state_pod`, `state_container`, `state_job`, `state_cronjob`, `state_statefulset`, `state_service`, `state_persistentvolume`, `state_persistentvolumeclaim`, `state_storageclass`, `pod`, `container`, `node`.
- The reason that these metricsets trigger the metadata enrichment is because of the way they start.
- All `state_metricsets` (except `state_container`) trigger the shared [kubernetes.Init](https://github.com/constanca-m/beats/blob/8fcdfc205ebe0221ed7a1046c673c9babfb5280d/metricbeat/module/kubernetes/state_daemonset/state_daemonset.go#L45) function when they get initialized.
- [kubernetes.Init](https://github.com/constanca-m/beats/blob/8fcdfc205ebe0221ed7a1046c673c9babfb5280d/metricbeat/helper/kubernetes/state_metricset.go#L44) calls the [New metricsets method](https://github.com/constanca-m/beats/blob/8fcdfc205ebe0221ed7a1046c673c9babfb5280d/metricbeat/helper/kubernetes/state_metricset.go#L80), which returns a new metricset with resource metadata enricher as part of it.
- Node, pod, container, and `state_container` metricsets do not trigger the `kubernetes.Init` rather they implement their own [New method](https://github.com/constanca-m/beats/blob/8fcdfc205ebe0221ed7a1046c673c9babfb5280d/metricbeat/module/kubernetes/node/node.go#L66) with the enricher as part of the metricsets returned.
- All of the above metricsets trigger the [NewResourceMetadataEnricher](https://github.com/constanca-m/beats/blob/8fcdfc205ebe0221ed7a1046c673c9babfb5280d/metricbeat/helper/kubernetes/state_metricset.go#L84) with only the exception of the container and `state_container` metricsets which trigger the [NewContainerMetadataEnricher](https://github.com/constanca-m/beats/blob/8fcdfc205ebe0221ed7a1046c673c9babfb5280d/metricbeat/module/kubernetes/state_container/state_container.go#L118C23-L118C51).
- The [NewResourceMetadataEnricher](https://github.com/constanca-m/beats/blob/8fcdfc205ebe0221ed7a1046c673c9babfb5280d/metricbeat/module/kubernetes/util/kubernetes.go#L501) is the function responsible for creating and returning a metadata enricher.
- The enricher is responsible for the metadata enrichment. For that, resource watchers are used which are shared between the different metricsets. For example for pod metricset, a pod watcher, a namespace and node watcher are by default needed in addition to job and replicaset watcher based on the configuration. These watchers will be also used by other metricsets that require them
like state_pod, state_container, node, state_job etc.
- The shared watchers are stored in the module-level struct [resourceWatchers](https://github.com/constanca-m/beats/blob/8fcdfc205ebe0221ed7a1046c673c9babfb5280d/metricbeat/module/kubernetes/kubernetes.go#L102). The struct is initialized when the Kubernetes module [starts](https://github.com/constanca-m/beats/blob/8fcdfc205ebe0221ed7a1046c673c9babfb5280d/metricbeat/module/kubernetes/util/kubernetes.go#L124).
- Each time a watcher gets created it is added to the struct along with some watcher important data. The [struct](https://github.com/constanca-m/beats/blob/8fcdfc205ebe0221ed7a1046c673c9babfb5280d/metricbeat/module/kubernetes/util/kubernetes.go#L99) consists of a metaWatchersMap which has as key the name of the resource this watcher is watching(i.e. pod or node) and as value a [metaWatcher](https://github.com/constanca-m/beats/blob/8fcdfc205ebe0221ed7a1046c673c9babfb5280d/metricbeat/module/kubernetes/util/kubernetes.go#L86C6-L86C17) struct. 
- The metaWatcher struct holds all the relevant info for the specific watcher. These info include
    - The `watcher` refers to the actual [kubernetes.Watcher](https://github.com/elastic/elastic-agent-autodiscover/blob/17950767e42c50365ecdd842349649cd70998f22/kubernetes/watcher.go#L47) interface responsible for monitoring the specified resource.
    - The `started` boolean that holds the information if the watcher has started or not
    - The `metricsetsUsing` field which is a slice with all the metricsets that are currently sharing this watcher. For example a pod watcher can be shared between pod, state_pod, container, state_container metricsets
    - The enrichers map. The enricher is a struct that is bound to a metricset and does the actual metadata enrichment for the events of that metricset using an update function. The metaWatcher holds the information of all the enrichers of the metricsets that are using this watcher, so that it knows what to do in case a new watch event is triggered(i.e a pod gets updated. The pod watcher gets triggered. It needs to trigger the update function of all the enrichers that it has stored)
    - The `metadataObjects` field which functions like a set, consisting of all the ids of the objects(resources) that this watcher has been triggered for. The id looks like `namespace_name-resource_name`. The reason this is needed will be explained later.
    - `nodeScope` boolean indicates whether this watcher needs to monitor the specific resource only on the node where the beat/agent is running(For example, for pod metricset, nodescope is true meaning that the watcher needs to watch pods only in this node because the metricsets colletcs info only from local kubelet. This is not the case for state_pod where nodescope is false). 
    - The `restartWatcher` field is generally nil, signifying that there is no need for a new updated watcher.However, if the running watcher needs to be restarted for any reason, restartWatcher will be the new watcher. A reason that a running watcher may have to be restarted is in case it has been initially triggered by a metricset(i.e. pod) with nodescope true and then it was triggered again by metricsets(state_pod) with nodescope false. In that case the watch options need to change, so the old watcher must be stopped and the new restartWatcher must be started and take its place. More on that later.
- NewResourceMetadataEnricher function is called by a given metricset. Two different configurations are created. [config](https://github.com/constanca-m/beats/blob/8fcdfc205ebe0221ed7a1046c673c9babfb5280d/metricbeat/module/kubernetes/util/kubernetes.go#L508) holding metricset related configuration and [commonConfig](https://github.com/constanca-m/beats/blob/8fcdfc205ebe0221ed7a1046c673c9babfb5280d/metricbeat/module/kubernetes/util/kubernetes.go#L521C2-L521C14) which holds information specific to the metadata enrichment.
- After the metricset is mapped to a specifig resource (i.e state_pod is mapped to pod resource) [createAllWatchers](https://github.com/constanca-m/beats/blob/8fcdfc205ebe0221ed7a1046c673c9babfb5280d/metricbeat/module/kubernetes/util/kubernetes.go#L531) is called to create all needed watchers for this resource.
- createAllWatchers will first create the main watcher for that resource(i.e for pod resource it will be pod watcher) and then will try to create all the extra watchers needed. [getExtraWatchers](https://github.com/constanca-m/beats/blob/8fcdfc205ebe0221ed7a1046c673c9babfb5280d/metricbeat/module/kubernetes/util/kubernetes.go#L393C19-L393C35) will return all the extra watchers per resource. For example a pod resource needs node, namespace and (if configured) job and replicaset watchers.
- For each watcher that needs to be created [createWatcher](https://github.com/constanca-m/beats/blob/8fcdfc205ebe0221ed7a1046c673c9babfb5280d/metricbeat/module/kubernetes/util/kubernetes.go#L383C18-L383C31) is called.
- [CreateWatcher](https://github.com/constanca-m/beats/blob/8fcdfc205ebe0221ed7a1046c673c9babfb5280d/metricbeat/module/kubernetes/util/kubernetes.go#L253) function takes several arguments. 
    - `resourceName` is needed so that it will be the key in the resourceWatchers map where all the created watchers are stored.
    - `resource` is the resource object(i.e Kubernetes.Pod{}) and is a requirement of [kubernetes.NewNamedWatcher](https://github.com/constanca-m/beats/blob/8fcdfc205ebe0221ed7a1046c673c9babfb5280d/metricbeat/module/kubernetes/util/kubernetes.go#L284C19-L284C45) function which creates the actual watcher.
    - `options` are the watch options for a specific watcher. They act like watching filters. For example a pod watcher can be configured through the options to watch only for resources on a specific node or namespace, or watch all pods. In our case,  watchers triggered by metricsets collecting from kubelet(pod and container metricsets only) are configured with `nodescope` true which is then translated to an extra [option](https://github.com/constanca-m/beats/blob/8fcdfc205ebe0221ed7a1046c673c9babfb5280d/metricbeat/module/kubernetes/util/kubernetes.go#L229) to watch only resources of that node. On the other hand, all state_metricsets are configured with nodescope false, as we need the watchers to collect metadata from resources across the entire cluster. For example the leader node collecting state_pod metrics, when it will try to enrich a pod found in the metrics with metadata, this pod may be running on a different node than the leader. So in case the pod watcher was only watching for pods in the leader node it would not have found any relevant metadata for that pod. 
    - `client` is the kubernetes client needed for the watcher creation
    - `resourceWatchers` is the store that holds the info about the created watchers and their data. resourceWatchers get updated inside this function if a new watcher gets created.
    - `namespace` is a configuration option that reflects to the `options` field we mentioned above. If set by the user, then watchers are watching for resources only in that namespace.
    - `extraWatcher` boolean sets apart the watchers that are created as main watcher for a resource and the ones that are created as an extra watcher. For example for pod metricset, pod watcher is the main and node, namespace watchers are extra. This information is important, because the extra watchers (can only be node, namespace, job and replicaset) will never have the Node option set in their watch options. We will explain more. 
- The createWatcher function first checks if a watcher of that resource already [exists](https://github.com/constanca-m/beats/blob/8fcdfc205ebe0221ed7a1046c673c9babfb5280d/metricbeat/module/kubernetes/util/kubernetes.go#L276)
- If it does not exist it creates it and [stores](https://github.com/constanca-m/beats/blob/8fcdfc205ebe0221ed7a1046c673c9babfb5280d/metricbeat/module/kubernetes/util/kubernetes.go#L288C3-L288C18) it in the `resourceWatchers` struct. When creating a new metaWatcher struct, then `started` options set to false as the watcher has not been started yet(just created). The `metadataObjects`, `enrichers` and `metricsetsUsing` initiliazied to empty, the `restartWatcher` set to nil and the `nodeScope` according to the function input(except from cases when it is an extra watcher where it is hardcoded to false).
- If the watcher for that resource already exists, we check if it needs to be restarted. This situation can arise in specific cases. For instance, if a pod watcher has been created from a metricset like pod or container with nodeScope set to true (watching only from one node), and then another metricset like state_pod or state_container tries to create a pod watcher (which can happen only in the leader node), the watcher already exists. However, if we don't take any action in this scenario, the state_pod watcher would use a watcher that watches only from one node, leading to missing metadata, as described earlier. To address this, we need to update the watcher, mainly changing its watch options (removing options.Node). Unfortunately, a running watcher cannot be updated directly. Instead, we must stop it and create a new one with the correct watch options. The new restartWatcher must be identical to the old watcher, including the same handler function (more on that later), with the only difference being in the watch options. Consequently, the metaWatcher struct of the watcher gets updated with the restartWatcher. The process of stopping the old watcher and starting the new one is handled later on.
- After createAllWatchers function creates all the watchers that are needed and update the resourceWatchers struct, the code flow returns to NewResourceMetadataEnricher
- Now, let's delve into the creation of metadata generators and handler functions. Watchers, on their own, are responsible for subscribing to the Kubernetes API and monitoring changes in the resources they are configured to watch. Their primary function is to update their internal cache or store. However, to determine what actions to take when a change occurs, we rely on the so-called event handlers.
- Let's delve into the details of metadata generation for various resources. There is a difference between pod/service resources and all the rest.
In more details:
    - For resources like pods or services, the [createMetadataGenSpecific](https://github.com/constanca-m/beats/blob/8fcdfc205ebe0221ed7a1046c673c9babfb5280d/metricbeat/module/kubernetes/util/kubernetes.go#L540) function is invoked to create the metadata generator. The pod metadata generator or the service metadata generator, are structs defined in [elastic-agent-autodiscover](https://github.com/elastic/elastic-agent-autodiscover/blob/e47c0f013820d394460a21b688e45de1ac7628de/kubernetes/metadata/pod.go#L40) repo and implement a [metagen interface](https://github.com/elastic/elastic-agent-autodiscover/blob/e47c0f013820d394460a21b688e45de1ac7628de/kubernetes/metadata/metadata.go#L39)and are designed to utilize the necessary [watchers](https://github.com/elastic/elastic-agent-autodiscover/blob/e47c0f013820d394460a21b688e45de1ac7628de/kubernetes/metadata/metadata.go#L100) to collect([Generate](https://github.com/elastic/elastic-agent-autodiscover/blob/e47c0f013820d394460a21b688e45de1ac7628de/kubernetes/metadata/pod.go#L87)) metadata for a specific resource. For example for pod named redis in namespace default, these generators leverage the pod watcher, collect all node metadata using the node watcher store and all namespace metadata using the namespacewatcher store. It is important to note that these generators do not make any direct API calls for metadata collection. This has been done by the watchers who update their stores with the updated resources and their metadata. The generators retrieve the metadata for the required resource from the watcher's store. The metadata generation is triggered by calling the Generate method.. All that is needed for the metadata generation, is the Generate method to be triggered.
    - For all other resources (excluding pods or services), [createMetadataGen](https://github.com/constanca-m/beats/blob/8fcdfc205ebe0221ed7a1046c673c9babfb5280d/metricbeat/module/kubernetes/util/kubernetes.go#L416C6-L416C23) is called. 
    Depending on whether the specific resource is namespaced (e.g., deployment) or not (e.g., node), either[NewNamespaceAwareResourceMetadataGenerator](https://github.com/elastic/elastic-agent-autodiscover/blob/4554e51c00911209f8dfd463f52bc17f65e3f18f/kubernetes/metadata/resource.go#L62) or [NewResourceMetadataGenerator](https://github.com/elastic/elastic-agent-autodiscover/blob/4554e51c00911209f8dfd463f52bc17f65e3f18f/kubernetes/metadata/resource.go#L44C6-L44C34) is invoked. Both functions create a [Resource](https://github.com/elastic/elastic-agent-autodiscover/blob/4554e51c00911209f8dfd463f52bc17f65e3f18f/kubernetes/metadata/resource.go#L37C6-L37C14) struct that includes methods for metadata generation for a given resource kind, particularly the([Generate](https://github.com/elastic/elastic-agent-autodiscover/blob/4554e51c00911209f8dfd463f52bc17f65e3f18f/kubernetes/metadata/resource.go#L78)). NewNamespaceAwareResourceMetadataGenerator additionally utilizes [NewNamespaceMetadataGenerator](https://github.com/elastic/elastic-agent-autodiscover/blob/4554e51c00911209f8dfd463f52bc17f65e3f18f/kubernetes/metadata/namespace.go#L37C6-L37C14)namespace metadata from the relevant watcher's store. In summary, both createMetadataGenSpecific and createMetadataGen create metadata generators for each resource, implementing the Generate method to fetch all required metadata.
- At this stage, the focus is on crafting event handlers that make use of the previously defined metadata generators. The goal is to establish a handler function assigned to a watcher. When the watcher is triggered, either due to the appearance or update of a new pod, the assigned handler function is executed. This handler, in turn, invokes the metadata generator associated with that specific resource, utilizing its Generate method to collect relevant metadata. The gathered metadata is then stored in a metadata map, which is part of an enricher struct bound to a metricset. To elaborate further, when a metricset later gathers metrics from kubelet or ksm, the events are enriched with metadata. This metadata is retrieved from the map within the enricher's struct. Consequently, the enricher acts as a bridge, facilitating the integration of metadata collected by the event handler into the metrics collected by the metricset. 
- In more details, updateFunc(https://github.com/constanca-m/beats/blob/8fcdfc205ebe0221ed7a1046c673c9babfb5280d/metricbeat/module/kubernetes/util/kubernetes.go#L551) will be used as the resource watcher's add(i.e. new pod appears) and update(i.e. existing pod got a new label) handler. It is responsible for generating the metadata for a detected resource. This function is common for all kind or resources but the resource type is checked when the function get's called. It actually returns a  map[string]mapstr.M{} where the key is an id in the form of [namespace:resource_name](https://github.com/constanca-m/beats/blob/8fcdfc205ebe0221ed7a1046c673c9babfb5280d/metricbeat/module/kubernetes/util/kubernetes.go#L556)(i.e default:redis) in case the resource is namespaced. If it is not then the id is just the resource's [name](https://github.com/constanca-m/beats/blob/8fcdfc205ebe0221ed7a1046c673c9babfb5280d/metricbeat/module/kubernetes/util/kubernetes.go#L553). The value of the map is the result of the Generate method of each resource's metadata generator. For example, it generates metadata for a [pod resource](https://github.com/constanca-m/beats/blob/8fcdfc205ebe0221ed7a1046c673c9babfb5280d/metricbeat/module/kubernetes/util/kubernetes.go#L561) differently than it would for a [node](https://github.com/constanca-m/beats/blob/8fcdfc205ebe0221ed7a1046c673c9babfb5280d/metricbeat/module/kubernetes/util/kubernetes.go#L579). In essence, this function is a versatile handler that, based on the type of resource, extracts relevant metadata using the corresponding metadata generator. The resulting map, structured with resource identifiers and their associated metadata, serves as a crucial dataset for enriching events with context when metrics are later collected.
- [deleteFunc](https://github.com/constanca-m/beats/blob/8fcdfc205ebe0221ed7a1046c673c9babfb5280d/metricbeat/module/kubernetes/util/kubernetes.go#L609C2-L609C12)has a straightforward purpose: it serves as the delete handler for the resource watcher. When the function is called, it implies that a resource deletion has been detected. Upon detecting a resource deletion, the deleteFunc removes the corresponding ID key from the map. After deleting the ID key, the function returns the ID of the deleted resource. In essence, this function ensures that, upon detecting the deletion of a resource, the associated metadata is appropriately removed from the dataset, maintaining an accurate representation of the current state of resources.
- [indexFunc](https://github.com/constanca-m/beats/blob/8fcdfc205ebe0221ed7a1046c673c9babfb5280d/metricbeat/module/kubernetes/util/kubernetes.go#L627C2-L627C11) is designed to extract the ID of a resource from a metricset event. For example, when pod metricset constructs an event to be published to ES, it then needs to enrich it with metadata. This event is related to a specific pod in a specific namespace. The function parses the metricset event to extract the relevant information needed to construct the resource ID. The ID is typically constructed based on the namespace and resource name associated with the event. The ID is used to retrieve the corresponding metadata from the enricher's map.
- After the functions are created [buildMetadataEnricher](https://github.com/constanca-m/beats/blob/8fcdfc205ebe0221ed7a1046c673c9babfb5280d/metricbeat/module/kubernetes/util/kubernetes.go#L642) is called to create an [enricher](https://github.com/constanca-m/beats/blob/8fcdfc205ebe0221ed7a1046c673c9babfb5280d/metricbeat/module/kubernetes/util/kubernetes.go#L67) struct. The enricher struct is tied to a specific metricset. The one metricset that called the NewResourceMetadataEnricher function. In summary, buildMetadataEnricher is a crucial part of the architecture, creating the enricher struct that facilitates the association of metadata with metricset events.
- buildMetadataEnricher builds and returns a metadata enricher for a given metricset. The enricher struct implements a [Start](https://github.com/constanca-m/beats/blob/8fcdfc205ebe0221ed7a1046c673c9babfb5280d/metricbeat/module/kubernetes/util/kubernetes.go#L979) method that initiates the watchers associated with the enricher (metricset), a [Stop](https://github.com/constanca-m/beats/blob/8fcdfc205ebe0221ed7a1046c673c9babfb5280d/metricbeat/module/kubernetes/util/kubernetes.go#L1028) method that terminates the watchers associated with the enricher and an [Enrich](https://github.com/constanca-m/beats/blob/8fcdfc205ebe0221ed7a1046c673c9babfb5280d/metricbeat/module/kubernetes/util/kubernetes.go#L1055C20-L1055C26) method that is responsible for enriching metricset events with metadata..
- Relationship Between Enricher and Watcher:
    - The relationship between enrichers and watchers is not one-to-one but rather many-to-one.
    - For a specific resource kind (e.g., pod or node), there is only one watcher.
    - However, multiple metricsets may want to use the same watcher (e.g., pod, state_pod, state_container using the pod watcher).
    - The enrichers map in the [metaWatcher](https://github.com/constanca-m/beats/blob/8fcdfc205ebe0221ed7a1046c673c9babfb5280d/metricbeat/module/kubernetes/util/kubernetes.go#L92) struct serves as a connection between watchers and multiple metricset enrichers.
- This architecture efficiently handles the coordination between watchers and metricsets, ensuring that the appropriate metadata is collected and enriched for metricset events.
- buildMetadataEnricher function also [appends](https://github.com/constanca-m/beats/blob/8fcdfc205ebe0221ed7a1046c673c9babfb5280d/metricbeat/module/kubernetes/util/kubernetes.go#L876) the new enricher to the watcher.
- It also updates the [add](https://github.com/constanca-m/beats/blob/8fcdfc205ebe0221ed7a1046c673c9babfb5280d/metricbeat/module/kubernetes/util/kubernetes.go#L902), [update](https://github.com/constanca-m/beats/blob/8fcdfc205ebe0221ed7a1046c673c9babfb5280d/metricbeat/module/kubernetes/util/kubernetes.go#L927) and [delete](https://github.com/constanca-m/beats/blob/8fcdfc205ebe0221ed7a1046c673c9babfb5280d/metricbeat/module/kubernetes/util/kubernetes.go#L949) event handlers of the watcher to retrieve the metadata of all enrichers associated with that watcher. 
- Event Handler Mechanism:
    - The watcher's add, update, and delete event handlers (addFunc, updateFunc, deleteFunc) are updated to handle events for multiple enrichers.
    - When a new object(See obj in [line](https://github.com/constanca-m/beats/blob/8fcdfc205ebe0221ed7a1046c673c9babfb5280d/metricbeat/module/kubernetes/util/kubernetes.go#L902C18-L902C21)) is created or updated, these handlers gets triggered by the watcher internal mechanism.
    - They iterate over the enrichers map of the watcher and trigger the [UpdateFunc](https://github.com/constanca-m/beats/blob/8fcdfc205ebe0221ed7a1046c673c9babfb5280d/metricbeat/module/kubernetes/util/kubernetes.go#L919) of each enricher.
    - The UpdateFunc calls the Generate method of the metricset's metadata generator, obtaining the metadata map (newMetadataEvents).
    - The obtained metadata are then added to the enricher's metadata [map](https://github.com/constanca-m/beats/blob/8fcdfc205ebe0221ed7a1046c673c9babfb5280d/metricbeat/module/kubernetes/util/kubernetes.go#L922C7-L922C25) (enricher.metadata).
- Metadata Update Process: 
    - The buildMetadataEnricher function ensures that the watcher's event handlers are properly configured to update metadata for all associated enrichers.
    - This mechanism guarantees that when an event for a specific metricset arrives, the metadata map of the corresponding enricher is up-to-date.
    - The enricher's Enrich method can then utilize this metadata to enrich metricset events with the relevant information.
- But before doing that, there is an extra [step](https://github.com/constanca-m/beats/blob/8fcdfc205ebe0221ed7a1046c673c9babfb5280d/metricbeat/module/kubernetes/util/kubernetes.go#L878-L896). There is a scenario where existing resources (such as pods) trigger events before the corresponding enrichers (like state_pod) are initialized. To better understand this, let's think of the following scenario:
    - A new pod metricset gets initiliazed to start collecting kubelet metrics
    - NewResourceMetadataEnricher is called to create a new enricher for pod metadata
    - It creates a pod watcher
    - buildMetadataEnricher is called an the watcher.enrichers map includes only pod metricset's enricher
    - The pod watcher event handler will only call the updateFunc of the one enricher it has, when triggered
    - A new pod appears, the watcher handler function gets triggered and it executes the updatefunc of only the pod metricset's enricher
    - So the pod metricset's enricher's metadata map will have the metadata for all pod resources 
    - state_pod metricsets gets initiliazied. This happens in leader node. First pod metricsets starts and then state_pod
    - A new enricher for state_pod gets created, it uses the same existing pod watcher. Inside buildMetadataEnricher the watcher.enrichers map gets updated to include the state_pod enricher as well
    - So whenever a new pod appears or gets updated, both enricher's updateFunc will be triggered, so both enrichers' metadata map will be up to date
    - But what happens with pods that triggered a watcher event, in between the pod and state_pod initilization. So after the pod metricsets got initiliazed and before the state_pod got initiliazed
    - This is very common. The moment a watcher starts watching(from pod metricset) it immidiately gets notified for all pods in the cluster and executes whatever its updateFunc says. In that case the pod enricher's updateFunc
    - So when the watcher got updated with state_pod enricher, the events for the existing pods have already arrived and at that point the watcher did not call the state_pod's enricher updateFunc
    - Outcome is that the state_pod enricher's metadata map won't have the existing pods metadata, because the metadata generate method of that enricher was never called
    - So we need a way to handle those cases
- Watcher Initialization and MetadataObjects List:
   - Each `metaWatchersMap` contains a crucial field called `metadataObjects`.
   - This list is a record of all the object IDs (resource IDs) for which the watcher has been triggered.
- Updating MetadataObjects During Events:
   - Whenever the `AddFunc` or `UpdateFunc` of the watcher is triggered (e.g., when a new object is detected or an existing one is updated), the `metadataObjects` field is updated.
   - The ID of the detected object is [added](https://github.com/constanca-m/beats/blob/8fcdfc205ebe0221ed7a1046c673c9babfb5280d/metricbeat/module/kubernetes/util/kubernetes.go#L915) to the `metadataObjects` list.
- Proactive Synchronization with Existing Enrichers:
   - Before updating the watcher's event handlers with new enrichers in the `buildMetadataEnricher` function, the existing `metadataObjects` list is [iterated](https://github.com/constanca-m/beats/blob/8fcdfc205ebe0221ed7a1046c673c9babfb5280d/metricbeat/module/kubernetes/util/kubernetes.go#L883C43-L883C58).
- Enricher UpdateFunc Execution:
   - For each object ID in the `metadataObjects` list, the corresponding object is retrieved from the watcher's store.
   - The `UpdateFunc` of the new enricher (the one that called the buildMetadataEnricher e.g., state_pod) is then executed for each existing object, ensuring that the metadata map of the new enricher is updated with metadata for all existing objects.
- This systematic approach guarantees that the metadata for existing resources, which triggered events before the initialization of certain enrichers, is correctly captured and updated in the metadata map of the new enrichers.
- After the enricher gets created (during a metricset's initialization), then it gets started. This happens inside Fetch method of each [metricset](https://github.com/constanca-m/beats/blob/8fcdfc205ebe0221ed7a1046c673c9babfb5280d/metricbeat/helper/kubernetes/state_metricset.go#L104).
- [Start](https://github.com/constanca-m/beats/blob/8fcdfc205ebe0221ed7a1046c673c9babfb5280d/metricbeat/module/kubernetes/util/kubernetes.go#L979) method initiates the associated watchers, beginning with any extra watchers and then the primary watcher for the metricset. For example for pod metricset, we first start the namespace and node watcher and then the main pod watcher. This is intentional because if pod watcher starts first and gets triggered immediately(new pod appearance), then the namespace and node metadata won't be available as the namespace and node watcher haven't started yet.
- In cases where a watcher needs to be updated (e.g., changing watch options), a [restartWatcher](https://github.com/constanca-m/beats/blob/8fcdfc205ebe0221ed7a1046c673c9babfb5280d/metricbeat/module/kubernetes/util/kubernetes.go#L1003) is employed. This is applicable for pod watcher only. As already mentioned this can happen in leader nodes were a pod metricset created a watcher with nodescope(only watch for pods in current node), while state_pod needs the same watcher to watch pods in all nodes. 
- The existing watcher is stopped, and the restartWatcher takes its place, ensuring seamless transitions.
- The restartWatcher [replaces](https://github.com/constanca-m/beats/blob/8fcdfc205ebe0221ed7a1046c673c9babfb5280d/metricbeat/module/kubernetes/util/kubernetes.go#L1010) the initial watcher and restartWatcher is set to nil.
- Last step of the metadata enrichment process is the actual [Enrich](https://github.com/constanca-m/beats/blob/8fcdfc205ebe0221ed7a1046c673c9babfb5280d/metricbeat/module/kubernetes/util/kubernetes.go#L1055) method is called during the generation of events by [metricsets](https://github.com/constanca-m/beats/blob/8fcdfc205ebe0221ed7a1046c673c9babfb5280d/metricbeat/helper/kubernetes/state_metricset.go#L119).
- Inside Enrich, for each event(only metrics of same resource i.e redis pod), enrichers' [Index](https://github.com/constanca-m/beats/blob/8fcdfc205ebe0221ed7a1046c673c9babfb5280d/metricbeat/module/kubernetes/util/kubernetes.go#L1060) method identifies the associated resource, and metadata from the enricher's map are added to the event. Remember that the index method was created in the NewResourceMetadataEnricher function.
- So then the resource's metadata can be retrieved from the enricher's [metadata map](https://github.com/constanca-m/beats/blob/8fcdfc205ebe0221ed7a1046c673c9babfb5280d/metricbeat/module/kubernetes/util/kubernetes.go#L1060) and added to the event. Keep in mind that it was the watcher's event handler functions that had called all the relevant enrichers updateFunc to fill each enrichher's metadata map.
- Lastly, we have already explained in details the mechanism of NewResourceMetadataEnricher. However, for container and state_container metricsets [NewContainerMetadataEnricher](https://github.com/constanca-m/beats/blob/8fcdfc205ebe0221ed7a1046c673c9babfb5280d/metricbeat/module/kubernetes/util/kubernetes.go#L659) is called instead.
- The functionality is the same as NewResourceMetadataEnricher but as the resource is known(containers), the function operates as the resource was Pod. The reason is that we first need to collect pods and then get their containers. So it will only create pod related watchers and metadata generators.
- The difference comes to the creation of the enricher's updateFunc(https://github.com/constanca-m/beats/blob/8fcdfc205ebe0221ed7a1046c673c9babfb5280d/metricbeat/module/kubernetes/util/kubernetes.go#L701). In there, we need to first call pod metadata generator's [Generate](https://github.com/constanca-m/beats/blob/8fcdfc205ebe0221ed7a1046c673c9babfb5280d/metricbeat/module/kubernetes/util/kubernetes.go#L708) method (as it will also include the pod's containers metadata). Then we iterate the pod's [containers](https://github.com/constanca-m/beats/blob/8fcdfc205ebe0221ed7a1046c673c9babfb5280d/metricbeat/module/kubernetes/util/kubernetes.go#L723) and construct the [ID](https://github.com/constanca-m/beats/blob/8fcdfc205ebe0221ed7a1046c673c9babfb5280d/metricbeat/module/kubernetes/util/kubernetes.go#L752) of each container in the form of namespace:pod:container.
- The container metadata are also enriched a bit more with useful fields like `container.id`, `container.runtime`.


