[[logstash-output]]
=== Configure the Logstash output

++++
<titleabbrev>Logstash</titleabbrev>
++++

The Logstash output sends events directly to Logstash by using the lumberjack
protocol, which runs over TCP. Logstash allows for additional processing and routing of
generated events.

// tag::shared-logstash-config[]

[IMPORTANT]
.Prerequisite
To send events to {ls}, you also need to create a {ls} configuration pipeline
that listens for incoming Beats connections and indexes the received events into
{es}. For more information, see
{logstash-ref}/getting-started-with-logstash.html[Getting Started with {ls}].
Also see the documentation for the
{logstash-ref}/plugins-inputs-beats.html[{beats} input] and
{logstash-ref}/plugins-outputs-elasticsearch.html[{es} output] plugins.

If you want to use {ls} to perform additional processing on the data collected by
{beatname_uc}, you need to configure {beatname_uc} to use {ls}.

To do this, edit the {beatname_uc} configuration file to disable the {es}
output by commenting it out and enable the {ls} output by uncommenting the
logstash section:

[source,yaml]
------------------------------------------------------------------------------
#----------------------------- Logstash output --------------------------------
output.logstash:
  hosts: ["127.0.0.1:5044"]
------------------------------------------------------------------------------

The `hosts` option specifies the {ls} server and the port (`5044`) where {ls} is configured to listen for incoming
Beats connections.

For this configuration, you must <<load-template-manually,load the index template into {es} manually>>
because the options for auto loading the template are only available for the {es} output.

ifeval::["{beatname_lc}"=="filebeat"]
Want to use <<filebeat-modules,{beatname_uc} modules>> with {ls}? You need to do
some extra setup. For more information, see
{logstash-ref}/filebeat-modules.html[Working with {beatname_uc} modules].
endif::[]

// end::shared-logstash-config[]

==== Accessing metadata fields

Every event sent to Logstash contains the following metadata fields that you can
use in Logstash for indexing and filtering:

ifndef::apm-server[]
["source","json",subs="attributes"]
------------------------------------------------------------------------------
{
    ...
    "@metadata": { <1>
      "beat": "{beat_default_index_prefix}", <2>
      "version": "{version}" <3>
    }
}
------------------------------------------------------------------------------
<1> {beatname_uc} uses the `@metadata` field to send metadata to Logstash. See the
{logstash-ref}/event-dependent-configuration.html#metadata[Logstash documentation]
for more about the `@metadata` field.
<2> The default is {beat_default_index_prefix}. To change this value, set the
<<logstash-index,`index`>> option in the {beatname_uc} config file.
<3> The current version of {beatname_uc}.
endif::[]

ifdef::apm-server[]
["source","json",subs="attributes"]
------------------------------------------------------------------------------
{
    ...
    "@metadata": { <1>
      "beat": "{beat_default_index_prefix}", <2>
      "pipeline":"apm", <3>
      "version": "{version}" <4>
    }
}
------------------------------------------------------------------------------
<1> {beatname_uc} uses the `@metadata` field to send metadata to Logstash. See the
{logstash-ref}/event-dependent-configuration.html#metadata[Logstash documentation]
for more about the `@metadata` field.
<2> The default is {beat_default_index_prefix}. To change this value, set the
<<logstash-index,`index`>> option in the {beatname_uc} config file.
<3> The default pipeline configuration: `apm`. Additional pipelines can be enabled
with a {logstash-ref}/use-ingest-pipelines.html[Logstash pipeline config].
<4> The current version of {beatname_uc}.
endif::[]

You can access this metadata from within the Logstash config file to set values
dynamically based on the contents of the metadata.

For example, the following Logstash configuration file tells
Logstash to use the index reported by {beatname_uc} for indexing events
into Elasticsearch:

ifndef::apm-server[]
[source,logstash]
------------------------------------------------------------------------------

input {
  beats {
    port => 5044
  }
}

output {
  elasticsearch {
    hosts => ["http://localhost:9200"]
    index => "%{[@metadata][beat]}-%{[@metadata][version]}" <1>
  }
}
------------------------------------------------------------------------------
<1> `%{[@metadata][beat]}` sets the first part of the index name to the value
of the `beat` metadata field and `%{[@metadata][version]}` sets the second part to
the Beat's version. For example:
+{beat_default_index_prefix}-{version}+.
endif::[]

ifdef::apm-server[]
[source,logstash]
------
input {
    beats {
        port => 5044
    }
}

filter {
    if [@metadata][beat] == "apm" {
        if [processor][event] == "sourcemap" {
            mutate {
                add_field => { "[@metadata][index]" => "%{[@metadata][beat]}-%{[@metadata][version]}-%{[processor][event]}" } <1>
            }
        } else {
            mutate {
                add_field => { "[@metadata][index]" => "%{[@metadata][beat]}-%{[@metadata][version]}-%{[processor][event]}-%{+yyyy.MM.dd}" } <2>
            }
        }
    }
}

output {
    elasticsearch {
        hosts => ["http://localhost:9200"]
        index => "%{[@metadata][index]}"
    }
}
------
<1> Creates a new field named `@metadata.index`.
`%{[@metadata][beat]}` sets the first part of the index name to the value of the `beat` metadata field.
`%{[@metadata][version]}` sets the second part to {beatname_uc}'s version.
`%{[processor][event]}` sets the final part based on the APM event type.
For example: +{beat_default_index_prefix}-{version}-sourcemap+.
<2> In addition to the above rules, this pattern appends a date to the `index` name so Logstash creates a new index each day.
For example: +{beat_default_index_prefix}-{version}-transaction-{sample_date_0}+.
endif::[]

Events indexed into Elasticsearch with the Logstash configuration shown here
will be similar to events directly indexed by {beatname_uc} into Elasticsearch.

ifndef::apm-server[]
NOTE: If ILM is not being used, set `index` to `%{[@metadata][beat]}-%{[@metadata][version]}-%{+YYYY.MM.dd}` instead so Logstash creates an index per day, based on the `@timestamp` value of the events coming from Beats.
endif::[]

ifdef::apm-server[]
==== Logstash and ILM

When used with {apm-server-ref}/ilm.html[Index lifecycle management], Logstash does not need to create a new index each day.
Here's a sample Logstash configuration file that would accomplish this:

[source,logstash]
------
input {
    beats {
        port => 5044
    }
}

output {
    elasticsearch {
        hosts => ["http://localhost:9200"]
        index => "%{[@metadata][beat]}-%{[@metadata][version]}-%{[processor][event]}"
    }
}
------
endif::[]

==== Compatibility

This output works with all compatible versions of Logstash. See the
https://www.elastic.co/support/matrix#matrix_compatibility[Elastic Support
Matrix].

==== Configuration options

You can specify the following options in the `logstash` section of the
+{beatname_lc}.yml+ config file:

===== `enabled`

The enabled config is a boolean setting to enable or disable the output. If set
to false, the output is disabled.

ifndef::apm-server[]
The default value is `true`.
endif::[]
ifdef::apm-server[]
The default value is `false`.
endif::[]

[[hosts]]
===== `hosts`

The list of known Logstash servers to connect to. If load balancing is disabled, but
multiple hosts are configured, one host is selected randomly (there is no precedence).
If one host becomes unreachable, another one is selected randomly.

All entries in this list can contain a port number. The default port number 5044 will be used, if no number is given.

===== `compression_level`

The gzip compression level. Setting this value to 0 disables compression.
The compression level must be in the range of 1 (best speed) to 9 (best compression).

Increasing the compression level will reduce the network usage but will increase the cpu usage.

The default value is 3.

===== `escape_html`

Configure escaping of HTML in strings. Set to `true` to enable escaping.

The default value is `false`.

===== `worker`

The number of workers per configured host publishing events to Logstash. This
is best used with load balancing mode enabled. Example: If you have 2 hosts and
3 workers, in total 6 workers are started (3 for each host).

[[loadbalance]]
===== `loadbalance`

If set to true and multiple Logstash hosts are configured, the output plugin
load balances published events onto all Logstash hosts. If set to false,
the output plugin sends all events to only one host (determined at random) and
will switch to another host if the selected one becomes unresponsive. The default value is false.

["source","yaml",subs="attributes"]
------------------------------------------------------------------------------
output.logstash:
  hosts: ["localhost:5044", "localhost:5045"]
  loadbalance: true
  index: {beatname_lc}
------------------------------------------------------------------------------

===== `ttl`

Time to live for a connection to Logstash after which the connection will be re-established.
Useful when Logstash hosts represent load balancers. Since the connections to Logstash hosts
are sticky, operating behind load balancers can lead to uneven load distribution between the instances.
Specifying a TTL on the connection allows to achieve equal connection distribution between the
instances.  Specifying a TTL of 0 will disable this feature.

The default value is 0.

NOTE: The "ttl" option is not yet supported on an async Logstash client (one with the "pipelining" option set).

===== `pipelining`

Configures number of batches to be sent asynchronously to logstash while waiting
for ACK from logstash. Output only becomes blocking once number of `pipelining`
batches have been written. Pipelining is disabled if a value of 0 is
configured. The default value is 2.

===== `proxy_url`

The URL of the SOCKS5 proxy to use when connecting to the Logstash servers. The
value must be a URL with a scheme of `socks5://`. The protocol used to
communicate to Logstash is not based on HTTP so a web-proxy cannot be used.

If the SOCKS5 proxy server requires client authentication, then a username and
password can be embedded in the URL as shown in the example.

When using a proxy, hostnames are resolved on the proxy server instead of on the
client. You can change this behavior by setting the
<<logstash-proxy-use-local-resolver,`proxy_use_local_resolver`>> option.

["source","yaml",subs="attributes"]
------------------------------------------------------------------------------
output.logstash:
  hosts: ["remote-host:5044"]
  proxy_url: socks5://user:password@socks5-proxy:2233
------------------------------------------------------------------------------

[[logstash-proxy-use-local-resolver]]
===== `proxy_use_local_resolver`

The `proxy_use_local_resolver` option determines if Logstash hostnames are
resolved locally when using a proxy. The default value is false which means
that when a proxy is used the name resolution occurs on the proxy server.

[[logstash-index]]
===== `index`

The index root name to write events to. The default is the Beat name. For
example +"{beat_default_index_prefix}"+ generates +"[{beat_default_index_prefix}-]{version}-YYYY.MM.DD"+
indices (for example, +"{beat_default_index_prefix}-{version}-2017.04.26"+).

NOTE: This parameter's value will be assigned to the `metadata.beat` field. It
can then be accessed in Logstash's output section as `%{[@metadata][beat]}`.

===== `ssl`

Configuration options for SSL parameters like the root CA for Logstash connections. See
<<configuration-ssl>> for more information. To use SSL, you must also configure the
https://www.elastic.co/guide/en/logstash/current/plugins-inputs-beats.html[Beats input plugin for Logstash] to use SSL/TLS.

===== `timeout`

The number of seconds to wait for responses from the Logstash server before timing out. The default is 30 (seconds).

===== `max_retries`

ifdef::ignores_max_retries[]
{beatname_uc} ignores the `max_retries` setting and retries indefinitely.
endif::[]

ifndef::ignores_max_retries[]
The number of times to retry publishing an event after a publishing failure.
After the specified number of retries, the events are typically dropped.

Set `max_retries` to a value less than 0 to retry until all events are published.

The default is 3.
endif::[]

===== `bulk_max_size`

The maximum number of events to bulk in a single Logstash request. The default is 2048.

If the Beat sends single events, the events are collected into batches. If the Beat publishes
a large batch of events (larger than the value specified by `bulk_max_size`), the batch is
split.

Specifying a larger batch size can improve performance by lowering the overhead of sending events.
However big batch sizes can also increase processing times, which might result in
API errors, killed connections, timed-out publishing requests, and, ultimately, lower
throughput.

Setting `bulk_max_size` to values less than or equal to 0 disables the
splitting of batches. When splitting is disabled, the queue decides on the
number of events to be contained in a batch.


===== `slow_start`

If enabled only a subset of events in a batch of events is transferred per transaction.
The number of events to be sent increases up to `bulk_max_size` if no error is encountered.
On error the number of events per transaction is reduced again.

The default is `false`.

===== `backoff.init`

The number of seconds to wait before trying to reconnect to Logstash after
a network error. After waiting `backoff.init` seconds, {beatname_uc} tries to
reconnect. If the attempt fails, the backoff timer is increased exponentially up
to `backoff.max`. After a successful connection, the backoff timer is reset. The
default is 1s.

===== `backoff.max`

The maximum number of seconds to wait before attempting to connect to
Logstash after a network error. The default is 60s.
