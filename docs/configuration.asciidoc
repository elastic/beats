[[configuration]]
== Configuration

The Beat configuration file uses
http://yaml.org/[YAML] for its syntax. It consists of the following sections:

* <<configuration-shipper>>
* <<configuration-output>>
* <<configuration-run-options>>

[[configuration-shipper]]
=== Shipper

The shipper section contains options for the Beat shipper itself and some
general settings regarding its behaviour.

Example configuration:

[source,yaml]
------------------------------------------------------------------------------
shipper:
  # The name of the shipper that publishes the network data. It can be used to group
  # all the transactions sent by a single shipper in the web interface.
  # If this options is not defined, the hostname is used.
  #name:

  # The tags of the shipper are included in their own field with each
  # transaction published. Tags make it easy to group servers by different
  # logical properties.
  tags: ["service-X", "web-tier"]

  # Uncomment the following if you want to ignore transactions created
  # by the server on which the shipper is installed. This option is useful
  # to remove duplicates if shippers are installed on multiple servers.
  ignore_outgoing: true

  # How often (in seconds) shippers are publishing their IPs to the topology map.
  # The default is 10 seconds.
  refresh_topology_freq: 10

  # Expiration time (in seconds) of the IPs published by a shipper to the topology map.
  # All the IPs will be deleted afterwards. Note, that the value must be higher than
  # refresh_topology_freq. The default is 15 seconds.
  topology_expire: 15

  # Configure local GeoIP database support. If no paths are configured
  # the locations /usr/share/GeoIP/GeoLiteCity.dat and
  # /usr/local/var/GeoIP/GeoLiteCity.dat are searched for a GeoIP database.
  geoip:
    # If paths is empty, GeoIP support will be disabled.
    paths: ["/path/to/geoip/data/GeoLiteCity.dat"]
------------------------------------------------------------------------------

==== Options

===== name

The name of the Beat shipper. If empty, the `hostname` of the server is
used. This information is included in each transaction (the `shipper` field)
published by the shipper and it can be used to group all the transactions sent by
a single shipper.

At startup, every Beat shipper registers itself to the network topology by
publishing to Elasticsearch the IP and port together with its shipper name. This
information is used to set both the `server` and `client_server` fields
from transactions even when they are sniffed by another shipper.

Example:

[source,yaml]
------------------------------------------------------------------------------
shipper:
  name: "my-shipper"
------------------------------------------------------------------------------

===== tags

The tags of the shipper are included in the `tags` field with each transaction
published. Tags make it easy to group servers by different logical properties.
For example, if you have a cluster of web servers, you can add to the shippers on
each of them the tag "webservers" and then use filters and queries in the
Kibana web interface to get visualisations for the whole group of servers.

Example:

[source,yaml]
------------------------------------------------------------------------------
shipper:
  tags: ["my-service", "hardware", "test"]
------------------------------------------------------------------------------

===== ignore_outgoing

If the `ignore_outgoing` option is enabled, Beat shipper ignores all the
transactions initiated from the server running the shipper.

This is useful when two shippers publish the same transactions because one sees
it in its outgoing queue and the other sees it in its incoming queue. In order
to remove the duplications, you can enable this option on one of the servers.

image:./images/option_ignore_outgoing.png[Shippers Architecture]

For example, in case a shipper is installed on each server from a 3 servers
architecture, t1 is the transaction exchanged between Server1 and Server2 and
t2 is the transaction between Server2 and Server3, then both transactions are
indexed twice as Shipper2 sees both transactions:

Published transactions (ignore outgoing is false):

 - Shipper1: t1
 - Shipper2: t1 and t2
 - Shipper3: t2

To avoid duplications, you can enforce your shippers to send only the incoming
transactions and ignore the transactions created by the local server:

Published transactions (ignore outgoing is true):

 - Shipper1: none
 - Shipper2: t1
 - Shipper3: t2

===== refresh_topology_freq

This setting settings controls the refreshing interval of the topology map in
seconds. In other words, how often each shipper publishes its IP addresses to the
topology map. The default is 10 seconds.

===== topology_expire

This setting controls the expiration time for the topology in seconds. This is
useful in case a shipper stops publishing its IP addresses.  The IP addresses
are removed automatically from the topology map after expiration. The default
is 15 seconds.

===== geoip.paths

The geoip.paths setting configures the search path for the GeoIP databases. If no database can be loaded or geoip.paths is an empty list, GeoIP support is disabled. The first file found will be loaded.

If geoip.paths is missing from config file the default paths /usr/share/GeoIP/GeoLiteCity.dat and /usr/local/var/GeoIP/GeoLiteCity.dat are searched for installed GeoIP databases.

*Important*: For GeoIP support to function correctly the https://dev.maxmind.com/geoip/legacy/geolite/[GeoLite City database] is required.


[[configuration-output]]
=== Outputs

Multiple outputs can be configured for exporting the correlated transactions.
Currently the following output types are supported:

* Elasticsearch
* Logstash
* Redis
* File

One or multiple outputs can be enabled at a time. The output plugins are
responsible for sending the transaction data in JSON format to the next step in
the pipeline. In addition, they are also responsible for maintaining the
network topology.

==== Elasticsearch Output

Sends the transactions directly to Elasticsearch by using the Elasticsearch
HTTP API.

Example configuration:

[source,yaml]
------------------------------------------------------------------------------
output:
  elasticsearch:

    # Enable Elasticsearch as output
    enabled: true

    # The Elasticsearch cluster
    hosts: ["http://10.45.3.2", "http://10.45.3.1/elasticsearch"]

    # Comment this option if you don't want to store the topology in
    # Elasticsearch. The default is false.
    # This option makes sense only for Packetbeat
    save_topology: true

    # Optional index name. The default is packetbeat and generates
    # [packetbeat-]YYYY.MM.DD keys.
    index: "packetbeat"

    # List of root certificates for HTTPS server verifications
    cas: ["/etc/pki/root/ca.pem"]

    # TLS configuration.
    tls:
      # Certificate for TLS client authentication
      certificate: "/etc/pki/client/cert.pem"

      # Client Certificate Key
      certificatekey: "/etc/pki/client/cert.key"

------------------------------------------------------------------------------

To enable SSL, just add `https` to all URLs defined under __hosts__.

[source,yaml]
------------------------------------------------------------------------------

output:
  elasticsearch:
	
    # Enable Elasticsearch as output
    enabled: true

    # The Elasticsearch cluster
    hosts: ["https://10.45.3.2", "https://10.45.3.1"]

    # Comment this option if you don't want to store the topology in
    # Elasticsearch. The default is false.
    # This option makes sense only for Packetbeat
    save_topology: true

    # HTTP basic auth
    username: "admin"
    password: "s3cr3t"

------------------------------------------------------------------------------

If the Elasticsearch nodes are defined by `IP:PORT` then add `protocol: https` to your yaml file.

[source,yaml]
------------------------------------------------------------------------------

output:
  elasticsearch:

    # Enable Elasticsearch as output
    enabled: true

    # The Elasticsearch cluster
    hosts: ["10.45.3.2", "10.45.3.1"]

    # Optional http or https. Default is http
    protocol: "https"

    # Comment this option if you don't want to store the topology in
    # Elasticsearch. The default is false.
    # This option makes sense only for Packetbeat
    save_topology: true

    # HTTP basic auth
    username: "admin"
    password: "s3cr3t"

------------------------------------------------------------------------------


===== enabled

Boolean option that enables Elasticsearch as output. The default is true.

[[hosts-option]]
===== hosts

The list of Elasticsearch nodes to which to connect. The events are distributed to
these nodes in round robin order. If one node becomes unreachable, the event is
automatically sent to another node. Each Elasticsearch node can be defined as an `URL` or `IP:PORT`.
Examples: `http://192.15.3.2`, `https://es.found.io:9230` or `192.24.3.2:9300`.
If no port is specified, `9200` is used.

Note:: In case of `IP:PORT`, the _scheme_ and _path_ are taken from the <<protocol-option>> and <<path-option>> config
options. 

[source,yaml]
------------------------------------------------------------------------------
output:
  elasticsearch:

    # Enable Elasticsearch as output
    enabled: true

    # The Elasticsearch cluster
    hosts: ["10.45.3.2:9220", "10.45.3.1:9230"]

    # Optional http or https. Default is http
    protocol: https

    # HTTP Path at which each Elasticsearch server lives
    path: /elasticsearch
------------------------------------------------------------------------------

In the previous example, the Elasticsearch nodes are available at https://10.45.3.2:9220/elasticsearch and
https://10.45.3.1:9230/elasticsearch.


===== host (DEPRECATED)

The host of the Elasticsearch server. This option is deprecated as it is replaced by <<hosts-option>>.

===== port (DEPRECATED)

The port of the Elasticsearch server. This option is deprecated as it is replaced by <<hosts-option>>.


===== username

Basic authentication username for connecting to Elasticsearch.

===== password

Basic authentication password for connecting to Elasticsearch.

[[protocol-option]]
===== protocol

The name of the protocol Elasticsearch is reachable on. The options are:
`http` or `https`. The default is `http`. Its value is overwritten by the scheme available in the URL.

[[path-option]]
===== path

An HTTP path prefix that is prepended to the HTTP API calls. This is useful for
the cases where Elasticsearch listens behind an HTTP reverse proxy that exports
the API under a custom prefix.


===== index

The index root name where to write events to. The default is `packetbeat` and
generates `[packetbeat-]YYYY.MM.DD` indexes (e.g. `packetbeat-2015.04.26`).

The index root name where to write events to. The default is the beat its name.
For example `packetbeat` generates `[packetbeat-]YYYY.MM.DD` indexes (e.g. `packetbeat-2015.04.26`).


===== max_retries

The number of times a particular Elasticsearch index operation is attempted. If
the indexing operation doesn't succeed after this many retries, the events are
dropped. The default is 3.

===== bulk_max_size

The maximum number of events to bulk in a single Elasticsearch bulk API index request.
The default is 10000.

===== flush_interval

The number of seconds to wait for new events between two bulk API index requests.
If `bulk_max_size` is reached before this interval expires, addition bulk index
requests are made.

===== save_topology

Boolean that sets if the topology is kept in Elasticsearch. The default is
false. This option makes sense only for Packetbeat.

===== topology_expire

The time to live in seconds for the topology information that is stored in
Elasticsearch. The default is 15 seconds.

===== tls

Configure TLS parameters like certificate authority for HTTPS based connections.
If tls section is missing, the host CAs will be used for HTTPS connections to
elasticsearch.

See <<configuration-output-tls>> for available TLS configuration options.


[[logstash-output]]
==== Logstash Output

The logstash output sends the events directly to logstash using the lumberjack
protocol. The logstash-input-beats plugin must be installed and configured
in logstash. Logstash will allow for additional processing and routing of
generated events.

Every event send to logstash contains additional meta data for indexing and filtering:

[source,json]
------------------------------------------------------------------------------
{
    ...
    @metadata: {
      "index": "<beat>-<date>",
      "type": "<event type>"
    }
}
------------------------------------------------------------------------------

Logstash elasticsearch output can be configured to use metadata and event type
for indexing.

[source,logstash]
------------------------------------------------------------------------------
...

output {
  elasticsearch {
    host => "localhost"
    port => "9200"
    protocol => "http"
    index => "%{[@metadata][index]}"
    document_type => "%{[@metadata][type]}"
  }

  ...
}
------------------------------------------------------------------------------

Example configuration:
[source,yaml]
------------------------------------------------------------------------------
output:
  logstash:
    enabled: true

    hosts:
      - logstash1:12345
      - logstash2:12345
      - logstash3:12345

    # configure index prefix name
    index: mybeat

    # configure logstash plugin to loadbalance events between logstash instances
    loadbalance: true

    tls:
      # disable tls for testing (TLS must be disabled in logstash too)
      disabled: true
------------------------------------------------------------------------------

===== enabled

Boolean option that enables logstash output. The default is true.

===== hosts

List of known logstash servers to connect to. All entries in this list can
contain a port number. If no port number is given, the port options value is
used as default port number.

===== loadbalance

If set to true and multiple logstash hosts are configured, The output plugin will
load balance published events onto all logstash hosts. If set to false,
the output plugin will send all events to only one host (determined by random)
switching to another host if selected one becomes unresponsive.
The default value is false.

===== port

Default port to use if port number not given in hosts. The default port number
is 10200.

===== index

The index root name where to write events to. The default is the beat its name.
For example `packetbeat` generates `[packetbeat-]YYYY.MM.DD` indexes (e.g. `packetbeat-2015.04.26`).

===== tls

TLS configuration like root CA for the logstash connections. See
<<configuration-output-tls>> for TLS options. If missing or tls.disabled is set to
true, a TCP only connection is assumed. Logstash must also be configured to use
TCP for logstash input.

===== timeout

Logstash connection timeout waiting for responses from logstash server.

===== max_retries

The number of times a particular logstash send attempted is tried. If
the send operation doesn't succeed after this many retries, the events are
dropped. The default is 3.

It is up to the beat to decide to drop the event or try again sending the event
if it was dropped by the output plugin. If send operation doesn't succeed after
max_retries, the beat optionally will be notified about it.


[[redis-output]]
==== Redis Output

////
TODO: I think besides the list option, PUB-SUB is also supported here (there
was a pull request some time ago. But that's not documented yet.
////

Inserts the events in a Redis list. This output plugin is compatibile with
http://logstash.net/docs/1.4.2/inputs/redis[Redis input plugin] from Logstash,
so Redis can be used as queue between the Beat shippers and Logstash.

Example configuration:

[source,yaml]
------------------------------------------------------------------------------
output:

  redis:
    # Uncomment out this option if you want to output to Redis. The default is false.
    enabled: true

    # Set the host and port where to find Redis.
    host: "localhost"
    port: 6379

    # Uncomment out this option if you want to store the topology in Redis.
    # The default is false.
    save_topology: true

    # Optional index name. The default is packetbeat and generates packetbeat keys.
    index: "packetbeat"

    # Optional Redis database number where the events are stored
    # The default is 0.
    db: 0

    # Optional Redis database number where the topology is stored
    # The default is 1. It must have a different value than db.
    db_topology: 1

    # Optional password to authenticate with. By default, no
    # password is set.
    # password: ""

    # Optional Redis initial connection timeout in seconds.
    # The default is 5 seconds.
    timeout: 5

    # Optional interval for reconnecting to failed Redis connections.
    # The default is 1 second.
    reconnect_interval: 1
------------------------------------------------------------------------------


===== enabled

Boolean option that enables Redis as output. The default is false.

===== host

Host of the Redis server.

===== port

Port of the Redis server.

===== db

Redis database number where the events are published. The default is 0.

===== db_topology

Redis database number where the topology information is stored. The default is 1.

===== index

Name of the Redis list where the events are published. The default is
`packetbeat`.

===== password

Password to authenticate with. The default is no authentication.

===== timeout

Redis initial connection timeout in seconds. The default is 5 seconds.

===== reconnect_interval

Interval for reconnecting failed Redis connections. The default is 1 second.

==== File Output

[source,yaml]
------------------------------------------------------------------------------
output:

  # File as output
  # Options:
  # path: where to save the files
  # filename: name of the files
  # rotate_every_kb: maximum size of the files in path
  # number of files: maximum number of files in path
  file:
    enabled: true
    path: "/tmp/packetbeat"
    filename: packetbeat
    rotate_every_kb: 1000
    number_of_files: 7
------------------------------------------------------------------------------

Dumps the transactions in a file where each transaction is in a JSON format.
Currently, this output is used for testing, but it can be used as input for
Logstash.

===== enabled

Boolean option that enables File as output. The default is false.

===== path

Path to the directory where to save the generated files. The option is
mandatory.

===== filename

Name of the generated files. The default is `packetbeat` and it generates files: `packetbeat`, `packetbeat.1`, `packetbeat.2`, etc.

===== rotate_every_kb

Maximum size in kilobytes of each file. When this size is reached, the files are
rotated. The default value is 10 MB.

===== number_of_files

Maximum number of files under path. When this number of files is reached, the
oldest file is deleted and the rest are shifted from last to first. The default
is 7 files.

[[configuration-output-tls]]

==== TLS options

===== disabled

When set to true none of the TLS configuration options will be applied. Effect is similar to missing TLS configuration in output plugin.

===== certificate_authorities

List of root certificates for server verifications. If certificate_authorities is empty or not set, the trusted certificate authorities of the host system will be employed.

===== certificate: "/etc/pki/client/cert.pem"

Configure the certificate for optional TLS client authentication. If certificate
is not configured, client authentication is not available in client. Connection
may fail if server requests client authentication. If TLS server does not
require client authentication, the certificate will be loaded but not be
requested/used by server.

When configured, both certificate and certificate_key options are required.

===== certificate_key: "/etc/pki/client/cert.key"

Client certificate key required to configure certificate for client
authentication. If certificate is not configured, client authentication is
not available in client.

When configured, both certificate and certificate_key are required.

===== insecure

Controls whether the client verifies server certificates and host name.
If insecure is set to true, all server host names and certificates will be
accepted. In this mode TLS based connections are susceptible to
man-in-the-middle attacks. Use only for testing.

===== cipher_suites

Configure list of used cipher suites. First entry has highest priority. If cipher_suites config option is missing, the go crypto library its default suites configuration is used(recommended).


List of allowed cipher suites names and their meanings.

* 3DES:
  Cipher suites using tripple DES

* AES128/256:
  Cipher suites using AES with 128/256bit keys.

* CBC:
  Cipher using Cipher Block Chaining as block cipher mode.

* ECDHE:
  Cipher suites using Elliptic Curve Diffie-Hellman (DH) ephemeral key exchange.

* ECDSA:
  Cipher suites using Elliptic Curve Digital Signature Algorithm for authentication.

* GCM:
  Galois/Counter mode is used for symmetric key cryptography.

* RC4:
  Cipher suites using RC4.

* RSA:
  Cipher suites using RSA.

* SHA, SHA256, SHA384:
  Cipher suites using SHA-1, SHA-256 or SHA-384.

The following cipher suites are available:

* RSA-RC4-128-SHA (disabled by default - RC4 not recommended)
* RSA-3DES-CBC3-SHA
* RSA-AES128-CBC-SHA
* RSA-AES256-CBC-SHA
* ECDHE-ECDSA-RC4-128-SHA (disabled by default - RC4 not recommended)
* ECDHE-ECDSA-AES128-CBC-SHA
* ECDHE-ECDSA-AES256-CBC-SHA
* ECDHE-RSA-RC4-128-SHA (disabled by default- RC4 not recommended)
* ECDHE-RSA-3DES-CBC3-SHA
* ECDHE-RSA-AES128-CBC-SHA
* ECDHE-RSA-AES256-CBC-SHA
* ECDHE-RSA-AES128-GCM-SHA256 (TLS 1.2 only)
* ECDHE-ECDSA-AES128-GCM-SHA256 (TLS 1.2 only)
* ECDHE-RSA-AES256-GCM-SHA384 (TLS 1.2 only)
* ECDHE-ECDSA-AES256-GCM-SHA384 (TLS 1.2 only)

===== curve_types

Configure available curve types for ECDHE (Elliptic Curve Diffie-Hellman ephemeral key exchange).

Available elliptic curve types:

* P-256
* P-384
* P-521

[[configuration-run-options]]
=== Run options (optional)

The Beat shipper can drop privileges after creating the sniffing socket.
Root access is required for opening the socket but everything else requires no
privileges. Therefore, it is recommended to have the shipper switch users after
the initialization phase.  `uid` and `gid` settings set the User Id and Group
Id under which the shipper will run.

WARNING: Because on Linux Setuid doesn't change the uid of all threads, the Go
         garbage collector will continue to run as root. Also, note that process
         monitoring only works when running as root.

Example configuration:

[source,yaml]
------------------------------------------------------------------------------
runoptions:
  uid=501
  gid=501
------------------------------------------------------------------------------

