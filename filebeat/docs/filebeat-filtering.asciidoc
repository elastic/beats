[[filtering-and-enhancing-data]]
== Filtering and Enhancing the Exported Data

Your use case might require only a subset of the data exported by Filebeat, or
you might need to enhance the exported data (for example, by adding metadata).
Filebeat provides a couple of options for filtering and enhancing exported
data.

You can configure each prospector to include or exclude specific lines or files.
This allows you to specify different filtering criteria for each prospector.
To do this, you use the <<include-lines,`include_lines`>>,
<<exclude-lines,`exclude_lines`>>, and <<exclude-files,`exclude_files`>>
options under the `filebeat.prospectors` section of the config file (see
<<configuration-filebeat-options,Filebeat configuration options>>). The
disadvantage of this approach is that you need to implement a configuration
option for each filtering criteria that you need.

Another approach (the one described here) is to define processors to configure
global processing across all data exported by Filebeat.


[float]
[[using-processors]]
=== Processors

include::../../libbeat/docs/processors.asciidoc[]

[float]
[[drop-event-example]]
==== Drop Event Example

The following configuration drops all the DEBUG messages.

[source,yaml]
-----------------------------------------------------
processors:
 - drop_event:
     when:
        regexp:
           message: "^DBG:"
-----------------------------------------------------

To drop all the log messages coming from a certain log file:

[source,yaml]
----------------
processors:
 - drop_event:
     when:
        contains:
           source: "test"
----------------

[float]
[[decode-json-example]]
==== Decode JSON Example

In the following example, the fields exported by Filebeat include a
field, `inner`, whose value is a JSON object encoded as a string:

[source,json]
-----------------------------------------------------
{ "outer": "value", "inner": "{\"data\": \"value\"}" }
-----------------------------------------------------

The following configuration decodes the inner JSON object:

[source,yaml]
-----------------------------------------------------
filebeat.prospectors:
- paths:
    - input.json
  json.keys_under_root: true

processors:
  - decode_json_fields:
      fields: ["inner"]

output.console.pretty: true
-----------------------------------------------------

The resulting output looks something like this:

["source","json",subs="attributes"]
-----------------------------------------------------
{
  "@timestamp": "2016-12-06T17:38:11.541Z",
  "beat": {
    "hostname": "host.example.com",
    "name": "host.example.com",
    "version": "{version}"
  },
  "inner": {
    "data": "value"
  },
  "prospector": {
    "type": "log",
  },
  "offset": 55,
  "outer": "value",
  "source": "input.json",
  "type": "log"
}
-----------------------------------------------------

include::../../libbeat/docs/processors-using.asciidoc[]
