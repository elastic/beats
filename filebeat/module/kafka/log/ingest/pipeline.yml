description: Pipeline for parsing Kafka log messages
processors:
- set:
    field: event.ingested
    value: '{{_ingest.timestamp}}'
- grok:
    field: message
    trace_match: true
    patterns:
    - (?m)%{TIMESTAMP_ISO8601:kafka.log.timestamp}. %{LOGLEVEL:log.level} +%{JAVALOGMESSAGE:message}
      \(%{JAVACLASS:kafka.log.class}\)$[ \n]*(?'kafka.log.trace.full'.*)
    - (?m)\[%{TIMESTAMP_ISO8601:kafka.log.timestamp}\] \[%{LOGLEVEL:log.level} ?\] \[%{NOTSPACE:kafka.log.thread}\] \[%{NOTSPACE:kafka.log.class}\] \- %{GREEDYDATA:message}
- grok:
    field: message
    pattern_definitions:
      KAFKA_COMPONENT: '[^\]]*'
    patterns:
    - \[%{KAFKA_COMPONENT:kafka.log.component}\][,:.]? +%{JAVALOGMESSAGE:message}
    on_failure:
    - set:
        field: kafka.log.component
        value: unknown
- grok:
    field: kafka.log.trace.full
    ignore_missing: true
    patterns:
    - '%{JAVACLASS:kafka.log.trace.class}:\s*%{JAVALOGMESSAGE:kafka.log.trace.message}'
    on_failure:
    - remove:
        field: kafka.log.trace
- remove:
    field: kafka.log.trace.full
    ignore_missing: true
- set:
    copy_from: '@timestamp'
    field: event.created
- date:
    if: ctx.event.timezone == null
    field: kafka.log.timestamp
    target_field: '@timestamp'
    formats:
    - yyyy-MM-dd HH:mm:ss,SSS
    on_failure:
    - append:
        field: error.message
        value: '{{ _ingest.on_failure_message }}'
- date:
    if: ctx.event.timezone != null
    field: kafka.log.timestamp
    target_field: '@timestamp'
    formats:
    - yyyy-MM-dd HH:mm:ss,SSS
    timezone: '{{ event.timezone }}'
    on_failure:
    - append:
        field: error.message
        value: '{{ _ingest.on_failure_message }}'
- remove:
    field: kafka.log.timestamp
- set:
    field: event.kind
    value: event
- script:
    lang: painless
    source: >-
      def errorLevels = ["ERROR", "FATAL"];
      if (ctx?.log?.level != null) {
        if (errorLevels.contains(ctx.log.level)) {
          ctx.event.type = "error";
        } else {
          ctx.event.type = "info";
        }
      }
- grok:
    field: message
    trace_match: true
    patterns:
    - ^%{KAFKA_MESSAGE:kafka.message} with /%{IPV4:source.ip} \(SSL handshake failed\)
    pattern_definitions:
      KAFKA_MESSAGE: Failed authentication
    ignore_failure: true
- geoip:
    field: source.ip
    target_field: source.geo
    ignore_missing: true
- geoip:
    database_file: GeoLite2-ASN.mmdb
    field: source.ip
    target_field: source.as
    properties:
      - asn
      - organization_name
    ignore_missing: true
- rename:
    field: source.as.asn
    target_field: source.as.number
    ignore_missing: true
- rename:
    field: source.as.organization_name
    target_field: source.as.organization.name
    ignore_missing: true
- append: 
    field: related.ip
    value: '{{ source.ip }}'
    if: "ctx.source?.ip != null"
- script:
    lang: painless
    description: "Check if event.category authentication"
    if: ctx.kafka?.message != null
    source: >-
      if (ctx.kafka.message == "Failed authentication") {
        ctx.event.type = "logon-failed";
        ctx.event.category = "authentication";
        ctx.event.action = "start";
        ctx.event.outcome = "failure";
      }
- remove: 
    field: kafka.message
    ignore_missing: true
on_failure:
- set:
    field: error.log
    value: '{{ _ingest.on_failure_message }}'
